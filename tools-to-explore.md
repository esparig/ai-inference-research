CNCF:

KServe
vLLM
Seldon
TGI
Skypilot

EU:
Exo

Copilot suggestions:
TensorFlow Serving: A flexible, high-performance serving system for machine learning models, designed for production environments.

TorchServe: A tool for serving PyTorch models, developed by AWS and Facebook.

Triton Inference Server: Developed by NVIDIA, this tool provides an optimized cloud and edge inferencing solution.

BentoML: An open-source platform for high-performance ML model serving, which supports multiple frameworks and deployment options.

MLRun: An open-source MLOps orchestration tool that simplifies the deployment of ML models and integrates with Kubernetes.

Cortex: A platform for deploying machine learning models as APIs, which supports TensorFlow, PyTorch, and other frameworks.

Opyrator: Turns your ML code into microservices with web API, interactive GUI, and more.

GraphPipe: A tool that simplifies machine learning model deployment.

Ray Serve: A scalable model serving library built on Ray, which supports serving models from various ML frameworks.

MLflow: An open-source platform for managing the end-to-end machine learning lifecycle, including model serving.